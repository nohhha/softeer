### 리뷰
- 지난 주말 동안 팀원들과 대면으로 만나서 개발 작업을 진행했다. 확실히 온라인으로 하는 것보다 바로 얼굴 보고, 코드를 공유하며 직접적으로 소통 가능한 점에서 빠른 협업이 이루어졌다.
- 주말 동안 한 것은 ec2를 띄워서 spark 실행하기 여서 팀원과 아래와 같이 분업을 했다.
  - 1. 로컬에서 실행되는 spark 컨테이너 dockerfile 및 docker-compose.yml 구성, spark-job.py 실행
  - 2. ec2 띄우고 환경 세팅해서 로컬에서 돌아가던 spark-job.py 실행 확인하기.
  - 나는 2번을 맡았는데 이를 위해 ec2에 할당할 보안그룹, 역할, vpc IGW 설정, 등등 ec2 서버에 필요한 권한들을 설정하는데 많이 헤맸다.
  - 정말 신기하게도 로컬에서는 실행되는게 ec2에서는 오류가 발생했다. 주된 오류 중 하나로는 master와 worker 컨테이너가 서로 연결이 안 되는 문제였는데, docker-compose에서 master의 host-name 환경변수를 설정해줌으로써 해결됐다.
- 그러자 spark-job.py 실행을 하면 자꾸 ec2가 터지는 문제가 발생했다.
- 처음에는 스크립트가 잘못되었다고 생각했는데, 알고보니 인스턴스를 t4g.micro로 사용하면서 RAM이 1기가인 것이 문제였다. 그제서야 하나씩 올려서 실험해보라는 다노님의 말씀을 이해하고, small -> medium으로 늘려가면서 medium의 RAM 4GB에서 잘 실행이 되는 것을 확인했다.
- 전체적인 파이프라인은 전부 구성했고, 남은 시간에 추가적인 대시보드 구현, spark job 최적화 등을 진행할 것이다.

### 회고
- keep
- problem
  - 팀원들과 협업을 하면서 불가피하게 서로의 코드를 수정하면서 오류가 많이 발생했다. 하지만 기존 베이스 코드, 수정한 코드 공유가 잘 안 되어서 수정 이전의 코드를 사용하는 등 오류를 찾는데 시간이 오래 걸렸다.
    따라서 앞으로 협업할 때는 어떤 코드를 수정 중인지, 어느 부분을 수정했는지 바로바로 공유를 하면서 진행해야할 것 같다.
- try
